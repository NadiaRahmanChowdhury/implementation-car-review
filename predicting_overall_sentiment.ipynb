{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QHIpjCxOeIqb",
        "outputId": "b69e8d9d-a245-489c-f423-5af6fa574a94"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "from wordcloud import WordCloud\n",
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "\n",
        "from keras.layers import Input\n",
        "import tensorflow as tf\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.utils import to_categorical, pad_sequences\n",
        "from keras.models import Model\n",
        "from keras.layers import Embedding, Conv1D, GlobalMaxPooling1D, Dense, Dropout, concatenate\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, roc_curve, auc\n",
        "from keras.models import load_model"
      ],
      "metadata": {
        "id": "sibPuwpWek-d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "review = \" Purchased this 2002 CLK55 AMG in April 2006 with 30,000 miles only on it! Paid $42,500. Can't beat the power nor the handling its incredible! Why go out and buy an new M3 or CLS when you cant get one of these for a fraction of the price. 0-60 in 4.7! The looks are stunning and it catch's everyone's attention when you step on it!\"\n",
        "review2 = \" I purchased this in October of 2005 with 25,000 miles on the odo. for $43,500.  It is truely a dream to drive and good on gas too! You cant beat the handling and the 0-60 in 4.5- 5.0 is NICE. Mercedes has built a rocket that can unleash at anytime. The ride is a bit stiff but it sittin on 17 inch/40/45's. \"\n",
        "review3 = \" This car has been great. We picked it up in July, and have had it for a month now! Bought it with just over 20k miles, for under $40 grand! Amazing of fthe line, the best handling I've ever experienced, and great build quality!  You can't beat it for the price nor the speed!\""
      ],
      "metadata": {
        "id": "A84-sovxerEv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5ZMNBk8rQBEH",
        "outputId": "52dcc335-1c35-49a0-9ca2-b64d3c7cb4a3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocessing\n",
        "def preprocess_text(text):\n",
        "    # remove punctuations\n",
        "    text = re.sub('[^a-zA-Z]', ' ', text)\n",
        "    # convert to lowercase\n",
        "    text = text.lower()\n",
        "    # remove stopwords\n",
        "    stop_words = set(stopwords.words(\"english\"))\n",
        "    text = ' '.join([word for word in text.split() if word not in stop_words])\n",
        "    return text\n"
      ],
      "metadata": {
        "id": "3hri7jK78b5B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the saved model\n",
        "model = load_model('/content/drive/MyDrive/overall_sentiment_model.hdf5')\n",
        "\n",
        "df = pd.DataFrame(data={'review': [review]})\n",
        "\n",
        "df.head()\n",
        "\n",
        "df['review'] = df['review'].apply(preprocess_text)\n",
        "\n",
        "# Tokenization\n",
        "tokenizer = Tokenizer(num_words=5000)\n",
        "tokenizer.fit_on_texts(df['review'].values)\n",
        "\n",
        "# Convert text to sequences\n",
        "X_review = tokenizer.texts_to_sequences(df['review'].values)\n",
        "\n",
        "\n",
        "# Pad sequences\n",
        "max_sequence_length = 100\n",
        "X_review = pad_sequences(X_review, maxlen=max_sequence_length)\n",
        "print(df)\n",
        "# Perform prediction\n",
        "predictions = model.predict(X_review)\n",
        "print(predictions)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZxMTBTMue-1p",
        "outputId": "0f7ba04b-f860-4081-9f19-d06687c3c3cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "         review\n",
            "0  bad car hate\n",
            "1/1 [==============================] - 1s 941ms/step\n",
            "[[0.01443807 0.07808766 0.9074743 ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define class labels\n",
        "class_labels = ['Negative', 'Neutral', 'Positive']\n",
        "# Convert prediction probabilities to labels\n",
        "predictions_labels = []\n",
        "\n",
        "for prediction in predictions:\n",
        "    max_index = np.argmax(prediction)\n",
        "    predicted_label = class_labels[max_index]\n",
        "    predictions_labels.append(predicted_label)\n",
        "\n",
        "# Print predicted sentiment labels\n",
        "print(predictions_labels)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TcVvmxe7LUJT",
        "outputId": "c9f01b09-ddb4-4b64-c2f9-fc3616341d23"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Positive']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gce-ZzrSXWxe"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}